dataset_path: &repo BoKelvin/SLAKE

task: "slake"

# Native splits are: train / validation / test
dataset_kwargs:
  token: True           # not strictly required (public), but safe to keep
test_split: test        # use "validation" if you prefer the val set

output_type: generate_until
doc_to_visual: !function utils.slake_doc_to_visual
doc_to_text: !function utils.slake_doc_to_text
doc_to_target: !function utils.slake_doc_to_target

generation_kwargs:
  max_new_tokens: 64
  do_sample: False

metric_list:
  - metric: accuracy
    aggregation: !function utils.slake_aggregate_results
    higher_is_better: true

process_results: !function utils.slake_process_results

metadata:
  - version: 0.0

lmms_eval_specific_kwargs:
  default:
    dataset_repo: *repo     # used by utils to auto-download imgs.zip
    # Filter to English by default (dataset has en/zh). Change to "zh" to evaluate Chinese.
    q_lang: "en"
    pre_prompt: ""
    # Give the model a tiny nudge for short answers
    post_prompt: "Answer concisely. If the answer is yes or no, reply exactly 'Yes' or 'No'."
